{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tables as tb\n",
    "import torch\n",
    "from torch_geometric.utils import segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.10.14\n",
      "IPython version      : 8.24.0\n",
      "\n",
      "torch          : 2.2.2\n",
      "torch_geometric: 2.5.2\n",
      "torch_scatter  : 2.1.2\n",
      "tables         : 3.9.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -p torch,torch_geometric,torch_scatter,tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6391562, 320])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file = \"../../../data/raw/esm2_t6_8M/hq_viruses_cleaned.filtered.GRAPHFMT.h5\"\n",
    "\n",
    "# to use torch_geometric.uitls.segment, these need to be torch tensors and NOT numpy arrays\n",
    "with tb.open_file(data_file) as fp:\n",
    "    ptn_embed = torch.from_numpy(fp.root.data[:])\n",
    "    genome_ptr = torch.from_numpy(fp.root.ptr[:])\n",
    "\n",
    "\n",
    "# the ptn embeddings are stored in a stacked batch\n",
    "# this is a 2D tensor of shape (num proteins, embed_dim)\n",
    "ptn_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([103590]),\n",
       " tensor([      0,       2,       4,  ..., 6387660, 6389580, 6391562]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to keep track of where the proteins are for a given genome, we use the genome_ptr\n",
    "# the genome_ptr is a 1D tensor of shape (num genomes + 1)\n",
    "# the first element is always 0, and the last element is the total number of proteins\n",
    "# this storage is basically to the CSR format used in sparse matrices\n",
    "# see PyTorch-Geometric\n",
    "genome_ptr.shape, genome_ptr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find more information about this data handling and batching procedure as described by PyTorch-Geometric [here](https://pytorch-geometric.readthedocs.io/en/latest/get_started/introduction.html#mini-batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   2,    2,    2,  ..., 1912, 1920, 1982])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can get the number of proteins encoded by each genome like this:\n",
    "genome_ptr[1:] - genome_ptr[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0674, -0.1024,  0.2181,  ...,  0.1273,  0.1046, -0.0729],\n",
       "         [-0.0429, -0.0993,  0.1606,  ...,  0.1879,  0.0067, -0.0889],\n",
       "         [ 0.0924,  0.1377,  0.0870,  ...,  0.1892, -0.3167, -0.1418],\n",
       "         ...,\n",
       "         [-0.0493, -0.1621,  0.1583,  ...,  0.0697,  0.0931, -0.0173],\n",
       "         [-0.0351, -0.1719,  0.2076,  ...,  0.0286,  0.0916,  0.0069],\n",
       "         [ 0.1466, -0.0786,  0.0592,  ...,  0.1793, -0.1845,  0.0206]]),\n",
       " torch.Size([8, 320]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the 8 protein embeddings for the 12346th genome can be retrieved like this:\n",
    "genome_idx = 12345\n",
    "start = genome_ptr[genome_idx]\n",
    "end = genome_ptr[genome_idx + 1]\n",
    "data = ptn_embed[start:end]\n",
    "data, data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0060, -0.2644,  0.1481,  ...,  0.0706,  0.1421,  0.0293],\n",
       "         [-0.1472, -0.1224,  0.0080,  ...,  0.1619,  0.0151, -0.0125],\n",
       "         [ 0.0055, -0.2752,  0.1366,  ...,  0.2125,  0.0188, -0.0243],\n",
       "         ...,\n",
       "         [-0.0525, -0.1741,  0.0631,  ...,  0.1884,  0.1247, -0.0510],\n",
       "         [-0.0386, -0.2544,  0.1082,  ...,  0.1716,  0.1657, -0.0124],\n",
       "         [-0.0468, -0.1754,  0.0623,  ...,  0.1929,  0.1073, -0.0620]]),\n",
       " torch.Size([103589, 320]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we use pytorch-geometric and pytorch-scatter to perform reductions on this stacked batch format using the genome_ptr\n",
    "# to average the protein embeddings per genome:\n",
    "genome_embed = segment(src=ptn_embed, ptr=genome_ptr, reduce=\"mean\")\n",
    "genome_embed, genome_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pst",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
